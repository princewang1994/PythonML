{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('car.data', 'r')\n",
    "car = pd.read_csv(f)\n",
    "sf = np.random.permutation(car.shape[0])\n",
    "car = car.iloc[sf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_row = range(car.shape[0] / 3 * 2)\n",
    "test_row = range(car.shape[0] / 3 * 2, car.shape[0])\n",
    "\n",
    "train_car = car.iloc[train_row]\n",
    "test_car = car.iloc[test_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_car.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HA(D, A):\n",
    "    n = D.shape[0]\n",
    "    values = D[A].unique()\n",
    "    DI = np.array([split(D, A, value).shape[0] for value in values])\n",
    "    P = DI / float(n)\n",
    "    return -np.sum(P * np.log(P))\n",
    "\n",
    "def entropy(D):\n",
    "    return HA(D, 'class')\n",
    "\n",
    "def H(D, a):\n",
    "    ent = [entropy(split(D, a, value)) for value in D[a].unique()]\n",
    "    size = [split(D, a, value).shape[0] for value in D[a].unique()]\n",
    "    return (np.array(ent) * np.array(size) / D.shape[0]).sum()\n",
    "\n",
    "def g(D, a):\n",
    "    return entropy(D) - H(D, a)\n",
    "\n",
    "def delta_ent_rate(D, a):\n",
    "    return g(D, a) / HA(D, a)\n",
    "\n",
    "def split(data, A, value):\n",
    "    return data[data[A] == value]\n",
    "\n",
    "def maxCntFeat(D):\n",
    "    label = D['class'].unique()\n",
    "    mLableIndex = np.argmax([D[D['class'] == lbl].shape[0] for lbl in label])\n",
    "    return label[mLableIndex]\n",
    "\n",
    "def createTree(data, features, eps=0.16):\n",
    "    n = data.shape[0]\n",
    "    cls = data['class']\n",
    "    if cls[cls == cls.iloc[0]].size == n:\n",
    "        return maxCntFeat(data), n\n",
    "    if features.size == 0:\n",
    "        return maxCntFeat(data), n\n",
    "\n",
    "    bestFeat = pd.Series({f: delta_ent_rate(data, f) for f in features}).argmax()\n",
    "    tree = {bestFeat : {}}\n",
    "    restFeat = np.delete(features, np.where(features == bestFeat)[0][0])\n",
    "    #print restFeat\n",
    "    \n",
    "    for value in car[bestFeat].unique():\n",
    "        Dv = split(data, bestFeat, value)\n",
    "        if Dv.shape[0] == 0:\n",
    "            tree[bestFeat][value] = maxCntFeat(data), 0\n",
    "        else:\n",
    "            tree[bestFeat][value] = createTree(split(data, bestFeat, value), restFeat)\n",
    "        \n",
    "    return tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classfy(tree, sample):\n",
    "    while True:\n",
    "        if type(tree) == tuple:\n",
    "            return tree[0]\n",
    "        feat = tree.keys()[0]\n",
    "        sampleFeat = sample[feat]\n",
    "        tree = tree[feat][sampleFeat]\n",
    "        \n",
    "def predict(tree, sample):\n",
    "    return np.array([classfy(tree, sample.iloc[i]) for i in range(sample.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91840277777777779"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = createTree(train_car, np.array(car.columns[:-1]))\n",
    "output = predict(tree, test_car)\n",
    "np.sum(test_car['class'].values == output) / float(output.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576L,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'high', 'med'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car['safety'].unique()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
